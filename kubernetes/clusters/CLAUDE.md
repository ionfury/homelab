# Kubernetes Clusters - Claude Reference

Per-cluster Flux bootstrap configurations that customize the centralized platform.

---

## Cluster Directory Structure

Each cluster has its own directory with bootstrap configuration:

```
clusters/<cluster-name>/
├── kustomization.yaml      # Entry point - generates ConfigMap from env files
├── platform.yaml           # References the centralized platform definition
├── .cluster-vars.env       # Cluster-specific variables (auto-generated by Terragrunt)
└── .versions.env           # Version pins (auto-generated by Terragrunt)
```

### File Purposes

| File | Purpose | Generated By |
|------|---------|--------------|
| `kustomization.yaml` | Flux entry point, configMapGenerator for cluster variables | Manual |
| `platform.yaml` | Kustomization referencing `../platform/` | Manual |
| `.cluster-vars.env` | Cluster identity variables (`cluster_name`, `internal_domain`, etc.) | Terragrunt |
| `.versions.env` | Version pins for cluster components | Terragrunt |

---

## Cluster-Specific Configuration

The `.cluster-vars.env` file provides cluster-specific variables that Flux substitutes at reconciliation time:

```env
cluster_name=dev
internal_domain=internal.dev.tomnowak.work
external_domain=external.dev.tomnowak.work
cluster_id=4
```

These variables are injected into the `flux-system` ConfigMap and used throughout the platform via `${variable_name}` substitution.

### When to Modify

- **Platform configuration** (shared across clusters): Edit files in `kubernetes/platform/`
- **Cluster-specific overrides**: Edit the cluster's `kustomization.yaml` patches
- **Cluster variables**: Regenerate via Terragrunt (don't edit `.cluster-vars.env` manually)

---

## Cluster Access

Each cluster has a separate kubeconfig file. **Every kubectl command must specify the KUBECONFIG**:

```bash
# Pattern: KUBECONFIG=~/.kube/<cluster>.yaml kubectl <command>
KUBECONFIG=~/.kube/dev.yaml kubectl get pods -A
KUBECONFIG=~/.kube/integration.yaml kubectl get nodes
KUBECONFIG=~/.kube/live.yaml kubectl describe pod -n monitoring prometheus-0
```

| Cluster | Kubeconfig Path |
|---------|-----------------|
| `dev` | `~/.kube/dev.yaml` |
| `integration` | `~/.kube/integration.yaml` |
| `live` | `~/.kube/live.yaml` |

**Important**: Do not rely on `kubectl config use-context` - always prefix commands with `KUBECONFIG=` to avoid accidentally targeting the wrong cluster.

---

## Available Clusters

| Name | Purpose | Hardware | Notes |
|------|---------|----------|-------|
| `live` | Production | node41-43 (Supermicro x86_64) | 3-node HA control plane |
| `integration` | Upgrade testing | node44 (Supermicro x86_64) | Single node, automated deployment |
| `dev` | Manual testing | rpi4, node46-48 (mixed ARM64/x86_64) | Multi-node, not in automated pipeline |

### Current Bootstrap State

| Cluster | Bootstrap Status |
|---------|------------------|
| `dev/` | Fully provisioned with all bootstrap files |
| `integration/` | Directory exists, bootstrap pending (generated by Terragrunt stack) |
| `live/` | Directory not yet created |

---

## Promotion Path

```
        dev (manual)              PR merged to main
             ↓                           ↓
    Create PR when ready    →    integration (auto)
                                         ↓
                                  Flux reports healthy
                                         ↓
                                   live (auto)
```

- **dev**: Manual experimentation space - use to validate changes before creating a PR
- **integration**: Receives changes automatically when PRs merge to `main`
- **live**: Receives changes automatically when Flux reports all resources healthy on `integration`

---

## Adding a New Cluster

1. Define hosts in `infrastructure/inventory.hcl` with cluster assignment
2. Create infrastructure stack in `infrastructure/stacks/<cluster>/`
3. Run Terragrunt to provision cluster and generate bootstrap files
4. Commit the generated `kubernetes/clusters/<cluster>/` files
5. Flux will bootstrap the cluster on next reconciliation
