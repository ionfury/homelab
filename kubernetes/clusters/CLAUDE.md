# Kubernetes Clusters - Claude Reference

Per-cluster Flux bootstrap configurations that customize the centralized platform.

---

## Cluster Directory Structure

Each cluster has its own directory with bootstrap configuration:

```
clusters/<cluster-name>/
├── kustomization.yaml      # Entry point - generates ConfigMaps from env files
├── platform.yaml           # References the centralized platform definition
├── config.yaml             # Cluster-specific config Kustomization
├── helm-charts.yaml        # Cluster-specific Helm releases ResourceSet
├── config/                 # Cluster-specific resources (Silences, PrometheusRules, etc.)
│   └── <subsystem>/
│       └── kustomization.yaml
├── charts/                 # Cluster-specific Helm values files
│   └── <release>.yaml
├── stubs/empty/            # Empty stub for wrapper Kustomizations
│   └── kustomization.yaml
└── .cluster-vars.env       # Cluster-specific variables (auto-generated by Terragrunt)
```

### File Purposes

| File | Purpose | Generated By |
|------|---------|--------------|
| `kustomization.yaml` | Flux entry point, configMapGenerator for cluster variables and values | Static (git) |
| `platform.yaml` | Kustomization referencing platform source (GitRepository for dev, OCIRepository for others) | Static (git) |
| `config.yaml` | Kustomization for cluster-specific config resources | Static (git) |
| `helm-charts.yaml` | ResourceSet for cluster-specific Helm releases | Static (git) |
| `.cluster-vars.env` | Cluster identity variables (`cluster_name`, `source_kind`, etc.) | Terragrunt |

---

## Per-Cluster Resources Pattern

This pattern enables deploying resources to specific clusters rather than platform-wide. Two resource types are supported:

### Config Resources (`config/`)

Cluster-specific Kubernetes resources like Silences, PrometheusRules, NetworkPolicies:

```yaml
# config.yaml deploys resources from config/ directory
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: cluster-config
spec:
  dependsOn:
    - name: platform  # Ensures CRDs exist
  path: kubernetes/clusters/<cluster>/config  # Hardcoded per cluster
  sourceRef:
    kind: GitRepository  # or OCIRepository for integration/live
    name: flux-system
```

**Note**: The `path` field must be hardcoded per cluster - Flux variable substitution only applies to resources *inside* the path, not to the Kustomization spec itself.

**Adding cluster-specific config:**
1. Create subdirectory in `config/` (e.g., `config/silences/`)
2. Add `kustomization.yaml` listing your resources
3. Add resource YAML files
4. Reference subdirectory in `config/kustomization.yaml`

### Helm Releases (`helm-charts.yaml`)

Cluster-specific Helm releases via ResourceSet (mirrors platform pattern):

```yaml
# Add entry to helm-charts.yaml inputs array
inputs:
  - name: "my-app"
    namespace: "my-namespace"
    chart:
      name: "app-template"
      version: "3.6.1"
      url: "oci://ghcr.io/bjw-s/helm"
    dependsOn: [kube-prometheus-stack]  # Can depend on platform releases
```

**Adding a cluster-specific Helm release:**
1. Add entry to `helm-charts.yaml` inputs array
2. Create `charts/<release-name>.yaml` with Helm values
3. Update `kustomization.yaml` configMapGenerator to include the values file:
   ```yaml
   - name: cluster-values
     files:
       - my-app.yaml=charts/my-app.yaml
   ```

### Dependency Model

```
platform.yaml (Kustomization)
    ↓ dependsOn
config.yaml (Kustomization)
    dependsOn: [platform]
helm-charts.yaml (ResourceSet)
    dependsOn: [platform] (can also depend on specific platform releases)
```

---

## Cluster-Specific Configuration

The `.cluster-vars.env` file provides cluster-specific variables that Flux substitutes at reconciliation time:

```env
cluster_name=dev
internal_domain=internal.dev.tomnowak.work
external_domain=external.dev.tomnowak.work
cluster_id=4
source_kind=GitRepository
```

These variables are injected into the `cluster-vars` ConfigMap and used throughout the platform via `${variable_name}` substitution.

### When to Modify

- **Platform configuration** (shared across clusters): Edit files in `kubernetes/platform/`
- **Cluster-specific resources**: Add to `config/` directory
- **Cluster-specific Helm releases**: Add to `helm-charts.yaml` and `charts/`
- **Cluster variables**: Regenerate via Terragrunt (don't edit `.cluster-vars.env` manually)

---

## Alertmanager Silences (silence-operator)

The [silence-operator](https://github.com/giantswarm/silence-operator) (deployed platform-wide) manages Alertmanager silences declaratively via `Silence` CRs. Silences are **per-cluster resources** placed in `config/silences/` because different clusters have different expected alert profiles.

### Silence CRD

```yaml
apiVersion: observability.giantswarm.io/v1alpha2
kind: Silence
metadata:
  name: descriptive-silence-name
  namespace: monitoring
spec:
  matchers:
    - name: alertname
      matchType: "=~"           # "=" for exact, "=~" for regex
      value: "Alert1|Alert2"
    - name: namespace
      matchType: "="
      value: target-namespace
```

### Matcher Reference

| Field | Values | Description |
|-------|--------|-------------|
| `matchType` | `=`, `!=`, `=~`, `!~` | Exact match, negation, regex match, regex negation |
| `name` | Any alert label | Common: `alertname`, `namespace`, `severity`, `job` |
| `value` | String or regex | Multiple alerts: `"Alert1\|Alert2\|Alert3"` |

### Adding a Cluster-Specific Silence

1. Create `config/silences/` directory if it doesn't exist
2. Add the Silence YAML file
3. Add to `config/silences/kustomization.yaml`
4. Reference `silences` in `config/kustomization.yaml`

### Zero-Alert Baseline

**Every cluster must maintain zero firing alerts** (excluding Watchdog, which validates Alertmanager is working). When an alert cannot be fixed (e.g., architectural limitation like single-node Spegel), silence it declaratively with a comment explaining why.

### Example: Dev-Only Silence

The dev cluster has a spegel silence because single-node clusters can't find P2P peers:

```
clusters/dev/
├── config/
│   ├── kustomization.yaml    # resources: [silences]
│   └── silences/
│       ├── kustomization.yaml    # resources: [spegel-single-node.yaml]
│       └── spegel-single-node.yaml
```

This silence only exists in dev - integration and live clusters don't have it.

---

## Cluster Access

Each cluster has a separate kubeconfig file. **Every kubectl command must specify the KUBECONFIG**:

```bash
# Pattern: KUBECONFIG=~/.kube/<cluster>.yaml kubectl <command>
KUBECONFIG=~/.kube/dev.yaml kubectl get pods -A
KUBECONFIG=~/.kube/integration.yaml kubectl get nodes
KUBECONFIG=~/.kube/live.yaml kubectl describe pod -n monitoring prometheus-0
```

| Cluster | Kubeconfig Path |
|---------|-----------------|
| `dev` | `~/.kube/dev.yaml` |
| `integration` | `~/.kube/integration.yaml` |
| `live` | `~/.kube/live.yaml` |

**Important**: Do not rely on `kubectl config use-context` - always prefix commands with `KUBECONFIG=` to avoid accidentally targeting the wrong cluster.

---

## Available Clusters

| Name | Purpose | Hardware | Notes |
|------|---------|----------|-------|
| `live` | Production | node41-43 (Supermicro x86_64) | 3-node HA control plane |
| `integration` | Upgrade testing | node44 (Supermicro x86_64) | Single node, automated deployment |
| `dev` | Manual testing | rpi4, node46-48 (mixed ARM64/x86_64) | Multi-node, not in automated pipeline |

### Current Bootstrap State

| Cluster | Source Type | Bootstrap Status |
|---------|-------------|------------------|
| `dev/` | GitRepository | Fully provisioned - syncs from git main branch |
| `integration/` | OCIRepository | Static files committed - syncs from `integration-*` tagged OCI artifacts |
| `live/` | OCIRepository | Static files committed - syncs from `validated-*` tagged OCI artifacts |

---

## Promotion Path

```
        dev (git-based)            PR merged to main
             ↓                           ↓
    Create PR when ready    →    GHA builds OCI artifact
                                  (integration-<sha>)
                                         ↓
                                  integration cluster
                                  (ImagePolicy auto-deploy)
                                         ↓
                                  canary-checker validation
                                         ↓
                                  GHA tags validated-<sha>
                                         ↓
                                    live cluster
                                  (ImagePolicy auto-deploy)
```

- **dev**: Git-based manual experimentation - use to validate changes before creating a PR
- **integration**: OCI artifact-based - auto-deploys `integration-*` tagged artifacts from GHCR
- **live**: OCI artifact-based - auto-deploys `validated-*` tagged artifacts after validation passes

---

## Adding a New Cluster

1. Define hosts in `infrastructure/inventory.hcl` with cluster assignment
2. Create infrastructure stack in `infrastructure/stacks/<cluster>/`
3. Run Terragrunt to provision cluster and generate bootstrap files
4. Commit the generated `kubernetes/clusters/<cluster>/` files
5. Flux will bootstrap the cluster on next reconciliation

---

## Network Policy Requirements

**Network policies are ENFORCED cluster-wide.** Application namespaces need proper labels or pods will have no network connectivity.

### Required Namespace Labels

Every application namespace must have a profile label in `kubernetes/platform/namespaces.yaml`:

```yaml
- name: my-app
  labels:
    network-policy.homelab/profile: standard  # Required for connectivity
```

| Profile | Use Case |
|---------|----------|
| `isolated` | Batch jobs, workers |
| `internal` | Internal dashboards |
| `internal-egress` | Internal apps calling external APIs |
| `standard` | Public-facing web apps |

### Optional Access Labels

```yaml
    access.network-policy.homelab/postgres: "true"   # Database access
    access.network-policy.homelab/garage-s3: "true"  # S3 storage
```

See [kubernetes/platform/config/network-policy/CLAUDE.md](../platform/config/network-policy/CLAUDE.md) for full documentation.
