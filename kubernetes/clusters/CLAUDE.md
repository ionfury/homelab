# Kubernetes Clusters - Claude Reference

Per-cluster Flux bootstrap configurations that customize the centralized platform.

---

## Cluster Directory Structure

Each cluster has its own directory with bootstrap configuration:

```
clusters/<cluster-name>/
├── kustomization.yaml      # Entry point - generates ConfigMap from env files
├── platform.yaml           # References the centralized platform definition
├── .cluster-vars.env       # Cluster-specific variables (auto-generated by Terragrunt)
└── .versions.env           # Version pins (auto-generated by Terragrunt)
```

### File Purposes

| File | Purpose | Generated By |
|------|---------|--------------|
| `kustomization.yaml` | Flux entry point, configMapGenerator for cluster variables | Static (git) |
| `platform.yaml` | Kustomization referencing platform source (GitRepository for dev, OCIRepository for others) | Static (git) |
| `.cluster-vars.env` | Cluster identity variables (`cluster_name`, `source_kind`, etc.) | Terragrunt |
| `.versions.env` | Version pins for cluster components | Terragrunt |

---

## Cluster-Specific Configuration

The `.cluster-vars.env` file provides cluster-specific variables that Flux substitutes at reconciliation time:

```env
cluster_name=dev
internal_domain=internal.dev.tomnowak.work
external_domain=external.dev.tomnowak.work
cluster_id=4
```

These variables are injected into the `flux-system` ConfigMap and used throughout the platform via `${variable_name}` substitution.

### When to Modify

- **Platform configuration** (shared across clusters): Edit files in `kubernetes/platform/`
- **Cluster-specific overrides**: Edit the cluster's `kustomization.yaml` patches
- **Cluster variables**: Regenerate via Terragrunt (don't edit `.cluster-vars.env` manually)

---

## Cluster Access

Each cluster has a separate kubeconfig file. **Every kubectl command must specify the KUBECONFIG**:

```bash
# Pattern: KUBECONFIG=~/.kube/<cluster>.yaml kubectl <command>
KUBECONFIG=~/.kube/dev.yaml kubectl get pods -A
KUBECONFIG=~/.kube/integration.yaml kubectl get nodes
KUBECONFIG=~/.kube/live.yaml kubectl describe pod -n monitoring prometheus-0
```

| Cluster | Kubeconfig Path |
|---------|-----------------|
| `dev` | `~/.kube/dev.yaml` |
| `integration` | `~/.kube/integration.yaml` |
| `live` | `~/.kube/live.yaml` |

**Important**: Do not rely on `kubectl config use-context` - always prefix commands with `KUBECONFIG=` to avoid accidentally targeting the wrong cluster.

---

## Available Clusters

| Name | Purpose | Hardware | Notes |
|------|---------|----------|-------|
| `live` | Production | node41-43 (Supermicro x86_64) | 3-node HA control plane |
| `integration` | Upgrade testing | node44 (Supermicro x86_64) | Single node, automated deployment |
| `dev` | Manual testing | rpi4, node46-48 (mixed ARM64/x86_64) | Multi-node, not in automated pipeline |

### Current Bootstrap State

| Cluster | Source Type | Bootstrap Status |
|---------|-------------|------------------|
| `dev/` | GitRepository | Fully provisioned - syncs from git main branch |
| `integration/` | OCIRepository | Static files committed - syncs from `integration-*` tagged OCI artifacts |
| `live/` | OCIRepository | Static files committed - syncs from `validated-*` tagged OCI artifacts |

---

## Promotion Path

```
        dev (git-based)            PR merged to main
             ↓                           ↓
    Create PR when ready    →    GHA builds OCI artifact
                                  (integration-<sha>)
                                         ↓
                                  integration cluster
                                  (ImagePolicy auto-deploy)
                                         ↓
                                  canary-checker validation
                                         ↓
                                  GHA tags validated-<sha>
                                         ↓
                                    live cluster
                                  (ImagePolicy auto-deploy)
```

- **dev**: Git-based manual experimentation - use to validate changes before creating a PR
- **integration**: OCI artifact-based - auto-deploys `integration-*` tagged artifacts from GHCR
- **live**: OCI artifact-based - auto-deploys `validated-*` tagged artifacts after validation passes

---

## Adding a New Cluster

1. Define hosts in `infrastructure/inventory.hcl` with cluster assignment
2. Create infrastructure stack in `infrastructure/stacks/<cluster>/`
3. Run Terragrunt to provision cluster and generate bootstrap files
4. Commit the generated `kubernetes/clusters/<cluster>/` files
5. Flux will bootstrap the cluster on next reconciliation
